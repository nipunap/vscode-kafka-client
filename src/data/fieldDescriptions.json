{
  "topic": {
    "Name": "Unique identifier for this topic",
    "Topic": "Unique identifier for this topic",
    "Topic Name": "Unique identifier for this topic",
    "Partitions": "Number of partitions - higher means more parallelism for producers and consumers",
    "Partition Count": "Number of partitions - higher means more parallelism for producers and consumers",
    "Replication Factor": "Number of replicas per partition - higher means more fault tolerance (recommended: 3 for production)",
    "Replicas": "Broker IDs that store copies of this partition data",
    "ISR": "In-Sync Replicas - replicas that are fully caught up with the leader",
    "In-Sync Replicas": "Replicas that are fully caught up with the leader and can become leader if needed",
    "Leader": "Broker ID that handles all reads and writes for this partition",
    "Cleanup Policy": "How old messages are removed: 'delete' (time-based) or 'compact' (key-based deduplication)",
    "Retention": "How long messages are kept before deletion (e.g., 7 days, 24 hours)",
    "Retention Time": "How long messages are kept before deletion (e.g., 7 days, 24 hours)",
    "Retention Bytes": "Maximum size of partition before old messages are deleted",
    "Segment Size": "Size of individual log segment files on disk",
    "Segment Bytes": "Size of individual log segment files on disk",
    "Compression": "Compression codec used for messages (gzip, snappy, lz4, zstd, or none)",
    "Compression Type": "Compression codec used for messages (gzip, snappy, lz4, zstd, or none)",
    "Min ISR": "Minimum in-sync replicas required for writes to succeed (ensures durability)",
    "Min In-Sync Replicas": "Minimum in-sync replicas required for writes to succeed (ensures durability)",
    "Max Message Size": "Maximum size of a single message the broker will accept",
    "Max Message Bytes": "Maximum size of a single message the broker will accept"
  },
  "topic_config": {
    "cleanup.policy": "How old segments are removed: 'delete' (time/size-based) or 'compact' (keep latest per key)",
    "compression.type": "Compression codec for messages: producer, gzip, snappy, lz4, zstd, or uncompressed",
    "delete.retention.ms": "Time to retain delete tombstone markers for compacted topics (default: 24 hours)",
    "file.delete.delay.ms": "Time to wait before deleting log segments from disk (default: 60 seconds)",
    "flush.messages": "Number of messages to accumulate before forcing a flush to disk (default: unlimited)",
    "flush.ms": "Maximum time between flushes to disk (default: unlimited)",
    "follower.replication.throttled.replicas": "List of replicas for which log replication should be throttled on follower side",
    "index.interval.bytes": "Interval at which log index entries are added (default: 4096 bytes)",
    "leader.replication.throttled.replicas": "List of replicas for which log replication should be throttled on leader side",
    "max.compaction.lag.ms": "Maximum time a message will remain uncompacted in the log",
    "max.message.bytes": "Maximum size of a message batch (default: 1MB, max recommended: 10MB)",
    "message.downconversion.enable": "Enable down-conversion of message formats for older consumers (impacts performance)",
    "message.format.version": "Message format version used by the broker (should match cluster version)",
    "message.timestamp.difference.max.ms": "Maximum allowed difference between message timestamp and broker time",
    "message.timestamp.type": "Timestamp type: CreateTime (set by producer) or LogAppendTime (set by broker)",
    "min.cleanable.dirty.ratio": "Minimum ratio of dirty log to total log before compaction triggers (default: 0.5)",
    "min.compaction.lag.ms": "Minimum time a message will remain uncompacted in the log",
    "min.insync.replicas": "Minimum number of replicas that must acknowledge a write for it to succeed (recommended: 2)",
    "preallocate": "Whether to preallocate disk space for new log segments (improves performance, uses more space)",
    "retention.bytes": "Maximum size of log before old segments are deleted (-1 = unlimited)",
    "retention.ms": "Maximum time to retain messages before deletion (default: 7 days, -1 = unlimited)",
    "segment.bytes": "Size of a single log segment file (default: 1GB)",
    "segment.index.bytes": "Maximum size of the offset index for a log segment (default: 10MB)",
    "segment.jitter.ms": "Maximum random jitter subtracted from scheduled segment roll time",
    "segment.ms": "Maximum time before a new log segment is rolled (default: 7 days)",
    "unclean.leader.election.enable": "Allow out-of-sync replicas to become leader (risks data loss, not recommended)"
  },
  "consumer": {
    "Group": "Unique identifier for this consumer group",
    "Group ID": "Unique identifier for this consumer group",
    "Consumer Group": "Unique identifier for this consumer group",
    "State": "Current state: Stable (healthy), Empty (no consumers), Dead (inactive), or Rebalancing",
    "Protocol": "Assignment strategy used to distribute partitions among consumers (range, roundrobin, sticky)",
    "Protocol Type": "Type of protocol used by the group (consumer for regular consumers)",
    "Members": "Number of active consumers in this group",
    "Member Count": "Number of active consumers in this group",
    "Coordinator": "Broker ID responsible for managing this consumer group",
    "Lag": "Number of messages behind the latest offset - higher means consumers are falling behind",
    "Total Lag": "Sum of lag across all partitions - total messages behind",
    "Current Offset": "Last committed offset - position in the partition where consumer last processed",
    "Log End Offset": "Latest offset in the partition - total messages produced",
    "Offset": "Position in the partition log (message number)",
    "Member ID": "Unique identifier for a consumer instance",
    "Client ID": "Application-defined identifier for the client",
    "Host": "Hostname or IP address of the consumer",
    "Assignment Strategy": "Algorithm used to assign partitions to consumers (range, roundrobin, sticky, cooperative-sticky)"
  },
  "consumer_config": {
    "auto.offset.reset": "What to do when no initial offset: 'earliest' (start from beginning), 'latest' (only new), or 'none' (throw error)",
    "enable.auto.commit": "Automatically commit offsets periodically in the background (default: true)",
    "auto.commit.interval.ms": "Frequency in milliseconds for auto-committing offsets (default: 5 seconds)",
    "fetch.max.bytes": "Maximum data broker will return in a single fetch (default: 50MB)",
    "fetch.min.bytes": "Minimum data broker should return in a fetch - broker waits until this much data (default: 1 byte)",
    "fetch.max.wait.ms": "Maximum time broker will wait before responding to fetch if min bytes not met (default: 500ms)",
    "group.id": "Unique identifier for the consumer group this consumer belongs to",
    "heartbeat.interval.ms": "Expected time between heartbeats to the coordinator (default: 3 seconds)",
    "isolation.level": "Controls how transactional messages are read: 'read_uncommitted' or 'read_committed'",
    "max.partition.fetch.bytes": "Maximum data per-partition broker will return (default: 1MB)",
    "max.poll.interval.ms": "Maximum delay between invocations of poll() before consumer is considered dead (default: 5 minutes)",
    "max.poll.records": "Maximum number of records returned in a single call to poll() (default: 500)",
    "partition.assignment.strategy": "Strategy for assigning partitions: RangeAssignor, RoundRobinAssignor, StickyAssignor, CooperativeStickyAssignor",
    "session.timeout.ms": "Timeout for detecting consumer failures (default: 10 seconds, range: 6-300 seconds)"
  },
  "broker": {
    "Broker": "Server that stores and serves Kafka data",
    "Broker ID": "Unique identifier for this broker in the cluster",
    "Host": "Hostname or IP address where the broker is running",
    "Port": "Network port the broker listens on",
    "Rack": "Rack identifier for rack-aware partition placement (improves fault tolerance)",
    "Controller": "The broker currently acting as cluster controller (manages partition leadership)",
    "Version": "Kafka broker version",
    "Log Dirs": "Directories where log segments are stored on disk",
    "Partition Leaders": "Number of partitions where this broker is the leader"
  },
  "broker_config": {
    "advertised.listeners": "Listeners advertised to clients - must be reachable by clients (differs from listeners if using proxy/NAT)",
    "allow.everyone.if.no.acl.found": "If no ACL found, allow everyone access (default: false for security)",
    "alter.config.policy.class.name": "Custom policy for validating alter config requests",
    "alter.log.dirs.replication.quota.window.num": "Number of samples for alter log dirs replication quotas",
    "alter.log.dirs.replication.quota.window.size.seconds": "Time window per sample for alter log dirs replication quotas",
    "auto.create.topics.enable": "Enable automatic topic creation when producer/consumer accesses non-existent topic. Default: true. AWS MSK default: false. Production: Set to false to prevent accidental topic creation with wrong configs (partitions=1, replication=1). Use explicit topic creation with proper settings instead.",
    "auto.include.jmx.reporter": "Automatically include JMX reporter for metrics (default: true)",
    "auto.leader.rebalance.enable": "Enable automatic leader rebalancing across brokers (default: true)",
    "authorizer.class.name": "Fully qualified class name of the authorizer (e.g., AclAuthorizer)",
    "background.threads": "Number of threads for background tasks like log cleaning (default: 10)",
    "broker.heartbeat.interval.ms": "Heartbeat interval for broker registration (KRaft mode)",
    "broker.id": "Unique identifier for this broker in the cluster (must be unique per broker)",
    "broker.id.generation.enable": "Enable automatic broker ID generation (default: true)",
    "broker.rack": "Rack ID for rack-aware replica placement (improves availability)",
    "broker.session.timeout.ms": "Timeout for broker session in KRaft mode",
    "client.quota.callback.class": "Custom callback for client quota calculations",
    "compression.type": "Default compression for topics without compression setting: producer, gzip, snappy, lz4, zstd",
    "connection.failed.authentication.delay.ms": "Delay before closing connection after failed authentication (prevents brute force)",
    "connections.max.idle.ms": "Idle connections closed after this time (default: 10 minutes)",
    "connections.max.reauth.ms": "Maximum time for reauthentication (0 = disabled)",
    "control.plane.listener.name": "Listener name for controller communication",
    "controlled.shutdown.enable": "Enable controlled shutdown of broker (default: true, allows clean handoff of partitions)",
    "controlled.shutdown.max.retries": "Number of retries for controlled shutdown (default: 3)",
    "controlled.shutdown.retry.backoff.ms": "Backoff time between shutdown retries (default: 5 seconds)",
    "controller.listener.names": "Comma-separated list of listener names for controller (KRaft mode)",
    "controller.quota.window.num": "Number of samples for controller quota",
    "controller.quota.window.size.seconds": "Time window per sample for controller quota",
    "controller.quorum.append.linger.ms": "Linger time for batching controller quorum appends",
    "controller.quorum.election.backoff.max.ms": "Maximum backoff time for controller elections",
    "controller.quorum.election.timeout.ms": "Timeout for controller quorum elections",
    "controller.quorum.fetch.timeout.ms": "Timeout for controller quorum fetches",
    "controller.quorum.request.timeout.ms": "Timeout for controller quorum requests",
    "controller.quorum.retry.backoff.ms": "Backoff time for controller quorum retries",
    "controller.quorum.voters": "Controller voter nodes in KRaft mode (id@host:port)",
    "controller.socket.timeout.ms": "Socket timeout for controller-to-broker channels (default: 30 seconds)",
    "create.topic.policy.class.name": "Custom policy for validating topic creation",
    "default.replication.factor": "Default replication factor for auto-created topics. Default: 1. AWS MSK: 3. Production: Set to 3 (or min 2) for fault tolerance. With RF=3, can tolerate 2 broker failures. Never use 1 in production - data loss if broker fails. Must be <= number of brokers in cluster.",
    "delegation.token.expiry.check.interval.ms": "Check interval for expiring delegation tokens",
    "delegation.token.expiry.time.ms": "Expiry time for delegation tokens (default: 24 hours)",
    "delegation.token.master.key": "Master key for delegation token encryption",
    "delegation.token.max.lifetime.ms": "Maximum lifetime for delegation tokens (default: 7 days)",
    "delegation.token.secret.key": "Secret key for delegation token signing",
    "delete.records.purgatory.purge.interval.requests": "Purge interval for delete records purgatory",
    "delete.topic.enable": "Enable topic deletion (default: true)",
    "early.start.listeners": "Listeners to start early before other startup",
    "fetch.max.bytes": "Maximum bytes broker will return in fetch (default: 55MB)",
    "fetch.purgatory.purge.interval.requests": "Purge interval for fetch purgatory",
    "group.initial.rebalance.delay.ms": "Delay before first rebalance after group formation (default: 3 seconds)",
    "group.max.session.timeout.ms": "Maximum session timeout for consumer groups (default: 5 minutes)",
    "group.max.size": "Maximum number of consumers in a single group",
    "group.min.session.timeout.ms": "Minimum session timeout for consumer groups (default: 6 seconds)",
    "initial.broker.registration.timeout.ms": "Timeout for initial broker registration (KRaft mode)",
    "inter.broker.listener.name": "Listener name for inter-broker communication",
    "inter.broker.protocol.version": "Inter-broker protocol version (should match cluster version)",
    "kafka.metrics.polling.interval.secs": "Interval for polling metrics reporters",
    "kafka.metrics.reporters": "List of custom metrics reporters",
    "leader.imbalance.check.interval.seconds": "Frequency of checking leader imbalance (default: 300 seconds)",
    "leader.imbalance.per.broker.percentage": "Percentage of leader imbalance allowed per broker before rebalance (default: 10%)",
    "listener.security.protocol.map": "Map of listener names to security protocols (e.g., PLAINTEXT:PLAINTEXT,SSL:SSL)",
    "listeners": "Comma-separated list of URIs and listener names that broker will bind to (e.g., PLAINTEXT://0.0.0.0:9092)",
    "log.cleaner.backoff.ms": "Backoff time when no logs need cleaning (default: 15 seconds)",
    "log.cleaner.dedupe.buffer.size": "Deduplication buffer size for log compaction (default: 128MB)",
    "log.cleaner.delete.retention.ms": "Time to retain delete tombstones (default: 24 hours)",
    "log.cleaner.enable": "Enable log cleaner process for compacted topics (default: true)",
    "log.cleaner.io.buffer.load.factor": "Load factor for log cleaner I/O buffers",
    "log.cleaner.io.buffer.size": "I/O buffer size for log cleaner (default: 512KB)",
    "log.cleaner.io.max.bytes.per.second": "I/O throttle for log cleaner (unlimited by default)",
    "log.cleaner.max.compaction.lag.ms": "Maximum time before log must be compacted",
    "log.cleaner.min.cleanable.ratio": "Minimum dirty ratio before compaction (default: 0.5 = 50%)",
    "log.cleaner.min.compaction.lag.ms": "Minimum time before log can be compacted",
    "log.cleaner.threads": "Number of log cleaner threads (default: 1)",
    "log.cleanup.policy": "Default cleanup policy: delete or compact (default: delete)",
    "log.dir": "Single directory for log data (deprecated, use log.dirs)",
    "log.dirs": "Comma-separated directories where log data is stored (use multiple for better I/O)",
    "log.flush.interval.messages": "Number of messages before forcing fsync of log (default: unlimited)",
    "log.flush.interval.ms": "Maximum time between fsyncs of log (default: unlimited)",
    "log.flush.offset.checkpoint.interval.ms": "Frequency of persisting log offset checkpoints",
    "log.flush.scheduler.interval.ms": "Frequency for log flusher to check if flush needed",
    "log.flush.start.offset.checkpoint.interval.ms": "Frequency of persisting log start offsets",
    "log.index.interval.bytes": "Interval for adding index entries (default: 4KB)",
    "log.index.size.max.bytes": "Maximum size of offset index (default: 10MB)",
    "log.message.downconversion.enable": "Enable down-conversion of message formats (impacts performance)",
    "log.message.format.version": "Message format version (deprecated, use inter.broker.protocol.version)",
    "log.message.timestamp.difference.max.ms": "Maximum allowed timestamp difference",
    "log.message.timestamp.type": "Timestamp type: CreateTime or LogAppendTime",
    "log.preallocate": "Preallocate log segment files (improves performance, uses more space)",
    "log.retention.bytes": "Maximum size of log before old segments deleted (default: -1 = unlimited)",
    "log.retention.check.interval.ms": "Frequency of checking logs for deletion (default: 5 minutes)",
    "log.retention.hours": "Time-based log retention in hours. Default: 168 (7 days). Precedence: log.retention.ms > log.retention.minutes > log.retention.hours. Common values: 168 (1 week), 720 (1 month), 2160 (3 months). Consider: Storage cost vs replay needs. Set -1 for unlimited (size-based only).",
    "log.retention.minutes": "Time-based log retention in minutes (overrides log.retention.hours). Rarely used - prefer log.retention.ms for precision or log.retention.hours for readability.",
    "log.retention.ms": "Time-based log retention in milliseconds (highest precedence, overrides hours/minutes). Default: null (uses log.retention.hours). Production: Use this for precise control. -1 = unlimited. Examples: 604800000 (7 days), 2592000000 (30 days). AWS MSK default: varies by cluster config.",
    "log.roll.hours": "Hours before a new log segment is rolled (default: 168 = 7 days)",
    "log.roll.jitter.hours": "Maximum jitter for log roll time (hours)",
    "log.roll.jitter.ms": "Maximum jitter for log roll time (milliseconds)",
    "log.roll.ms": "Milliseconds before a new log segment is rolled (overrides log.roll.hours)",
    "log.segment.bytes": "Maximum size of a single log segment file before rolling to new segment. Default: 1073741824 (1GB). AWS MSK: 1GB. Smaller segments: Faster log compaction, more files, higher overhead. Larger segments: Slower compaction, fewer files. Typical range: 512MB-2GB. Impact: Log retention works on segment granularity - can't delete partial segments.",
    "log.segment.delete.delay.ms": "Time to wait before deleting log segments (default: 60 seconds)",
    "max.connection.creation.rate": "Maximum rate of new connections per second",
    "max.connections": "Maximum number of connections broker will allow",
    "max.connections.per.ip": "Maximum connections from single IP address",
    "max.connections.per.ip.overrides": "Per-IP connection limit overrides",
    "max.incremental.fetch.session.cache.slots": "Maximum incremental fetch sessions",
    "message.max.bytes": "Maximum size of a message the broker will accept (default: 1MB)",
    "metadata.log.dir": "Directory for metadata log in KRaft mode",
    "metadata.log.max.record.bytes.between.snapshots": "Maximum bytes between metadata snapshots",
    "metadata.log.max.snapshot.interval.ms": "Maximum time between metadata snapshots",
    "metadata.log.segment.bytes": "Segment size for metadata log",
    "metadata.log.segment.ms": "Roll time for metadata log segments",
    "metadata.max.idle.interval.ms": "Maximum idle time for metadata cache",
    "metadata.max.retention.bytes": "Maximum size of metadata log",
    "metadata.max.retention.ms": "Maximum retention time for metadata log",
    "metric.reporters": "List of metrics reporters",
    "metrics.num.samples": "Number of samples for metrics",
    "metrics.recording.level": "Level for recording metrics (INFO or DEBUG)",
    "metrics.sample.window.ms": "Time window for metrics samples",
    "min.insync.replicas": "Minimum replicas that must acknowledge writes when producer uses acks=all. Default: 1. AWS MSK: 2. Production: Set to 2 (with RF=3) for durability without sacrificing availability. Formula: min.insync.replicas <= replication.factor. Setting to RF blocks writes if any replica fails. Best practice: RF=3, min.insync=2 balances durability and availability.",
    "node.id": "Node ID in KRaft mode",
    "num.io.threads": "Threads for disk I/O operations (read/write to log files). Default: 8. AWS MSK: 8. Tuning: Set to number of disks for parallel I/O. High throughput: 16-32 threads. Monitor: Track I/O wait time. More threads don't help if disk is bottleneck. Must restart broker to change.",
    "num.network.threads": "Threads for handling network requests (accepting connections, processing requests/responses). Default: 3. AWS MSK: 5. Tuning: Increase for high connection count or request rate. Typical: 8-16 for busy clusters. Monitor: Network processor idle %. Must restart broker to change.",
    "num.partitions": "Default number of partitions for auto-created topics (default: 1)",
    "num.recovery.threads.per.data.dir": "Number of threads per log directory for recovery at startup (default: 1)",
    "num.replica.alter.log.dirs.threads": "Threads for altering replica log directories",
    "num.replica.fetchers": "Number of fetcher threads for replicating messages from leader (default: 1)",
    "offset.metadata.max.bytes": "Maximum size of metadata for offset commit",
    "offsets.commit.required.acks": "Required acks for offset commits (default: -1 = all ISR)",
    "offsets.commit.timeout.ms": "Timeout for offset commit",
    "offsets.load.buffer.size": "Buffer size for loading offsets into cache",
    "offsets.retention.check.interval.ms": "Frequency of checking for stale offsets",
    "offsets.retention.minutes": "How long to retain committed offsets after consumer group becomes empty (all members leave). Default: 10080 minutes (7 days). AWS MSK: 7 days. Important: After this time, offsets are deleted and consumers must start from earliest/latest. Increase for groups that stop/start infrequently. Production: 20160 (14 days) or more for safety.",
    "offsets.topic.compression.codec": "Compression for __consumer_offsets topic",
    "offsets.topic.num.partitions": "Number of partitions for __consumer_offsets internal topic. Default: 50. AWS MSK: 50. Higher: Better parallelism for many consumer groups. Lower: Fewer resources. Cannot be changed after creation. Choose based on number of consumer groups: 50 works for most, 100-200 for very large clusters.",
    "offsets.topic.replication.factor": "Replication factor for __consumer_offsets internal topic. Default: 3. AWS MSK: 3. Critical: Losing this topic means all consumer offsets are lost. Production: Must match cluster's min.insync.replicas and default.replication.factor. Never set below 3. Cannot be changed after creation (must recreate cluster).",
    "offsets.topic.segment.bytes": "Segment size for __consumer_offsets topic",
    "password.encoder.cipher.algorithm": "Cipher algorithm for password encoding",
    "password.encoder.iterations": "Iterations for password encoding",
    "password.encoder.key.length": "Key length for password encoding",
    "password.encoder.keyfactory.algorithm": "Key factory algorithm for password encoding",
    "password.encoder.old.secret": "Old secret for password encoder rotation",
    "password.encoder.secret": "Secret for password encoding",
    "principal.builder.class": "Custom principal builder class for authentication",
    "process.roles": "Roles for this process in KRaft mode (broker, controller, or both)",
    "producer.id.expiration.ms": "Expiration time for producer IDs (default: 24 hours)",
    "producer.purgatory.purge.interval.requests": "Purge interval for producer purgatory",
    "queued.max.request.bytes": "Maximum queued request bytes before blocking",
    "queued.max.requests": "Maximum queued requests before blocking (default: 500)",
    "quota.window.num": "Number of samples for quota tracking",
    "quota.window.size.seconds": "Time window per sample for quota tracking",
    "replica.fetch.backoff.ms": "Backoff time when replica fetch has errors",
    "replica.fetch.max.bytes": "Maximum bytes for each partition replica fetcher (default: 1MB)",
    "replica.fetch.min.bytes": "Minimum bytes replica must fetch",
    "replica.fetch.response.max.bytes": "Maximum bytes for entire fetch response",
    "replica.fetch.wait.max.ms": "Maximum wait time for replica fetch",
    "replica.high.watermark.checkpoint.interval.ms": "Frequency of persisting high watermark",
    "replica.lag.time.max.ms": "Maximum time a follower can be behind before removed from ISR (default: 30 seconds)",
    "replica.selector.class": "Custom replica selector for consumer fetches",
    "replica.socket.receive.buffer.bytes": "Socket receive buffer for replication",
    "replica.socket.timeout.ms": "Socket timeout for replica fetches (default: 30 seconds)",
    "replication.quota.window.num": "Number of samples for replication quotas",
    "replication.quota.window.size.seconds": "Time window per sample for replication quotas",
    "request.timeout.ms": "Request timeout for clients (default: 30 seconds)",
    "reserved.broker.max.id": "Maximum broker ID that can be reserved",
    "sasl.client.callback.handler.class": "Custom callback handler for SASL client",
    "sasl.enabled.mechanisms": "Enabled SASL mechanisms (GSSAPI, PLAIN, SCRAM-SHA-256, etc.)",
    "sasl.jaas.config": "JAAS configuration for SASL",
    "sasl.kerberos.kinit.cmd": "Kerberos kinit command path",
    "sasl.kerberos.min.time.before.relogin": "Minimum time before Kerberos relogin",
    "sasl.kerberos.principal.to.local.rules": "Rules for mapping Kerberos principals",
    "sasl.kerberos.service.name": "Kerberos service name",
    "sasl.kerberos.ticket.renew.jitter": "Jitter for Kerberos ticket renewal",
    "sasl.kerberos.ticket.renew.window.factor": "Window factor for Kerberos ticket renewal",
    "sasl.login.callback.handler.class": "Custom callback handler for SASL login",
    "sasl.login.class": "Custom login class for SASL",
    "sasl.login.connect.timeout.ms": "Connection timeout for SASL login",
    "sasl.login.read.timeout.ms": "Read timeout for SASL login",
    "sasl.login.refresh.buffer.seconds": "Buffer time before credential expiration to refresh",
    "sasl.login.refresh.min.period.seconds": "Minimum refresh period for credentials",
    "sasl.login.refresh.window.factor": "Window factor for credential refresh",
    "sasl.login.refresh.window.jitter": "Jitter for credential refresh",
    "sasl.login.retry.backoff.max.ms": "Maximum backoff for SASL login retries",
    "sasl.login.retry.backoff.ms": "Initial backoff for SASL login retries",
    "sasl.mechanism.controller.protocol": "SASL mechanism for controller protocol",
    "sasl.mechanism.inter.broker.protocol": "SASL mechanism for inter-broker protocol",
    "sasl.oauthbearer.clock.skew.seconds": "Allowed clock skew for OAuth tokens",
    "sasl.oauthbearer.expected.audience": "Expected audience for OAuth tokens",
    "sasl.oauthbearer.expected.issuer": "Expected issuer for OAuth tokens",
    "sasl.oauthbearer.jwks.endpoint.refresh.ms": "Refresh interval for JWKS endpoint",
    "sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms": "Maximum backoff for JWKS retries",
    "sasl.oauthbearer.jwks.endpoint.retry.backoff.ms": "Initial backoff for JWKS retries",
    "sasl.oauthbearer.jwks.endpoint.url": "JWKS endpoint URL for OAuth",
    "sasl.oauthbearer.scope.claim.name": "Claim name for OAuth scope",
    "sasl.oauthbearer.sub.claim.name": "Claim name for OAuth subject",
    "sasl.oauthbearer.token.endpoint.url": "Token endpoint URL for OAuth",
    "sasl.server.callback.handler.class": "Custom callback handler for SASL server",
    "sasl.server.max.receive.size": "Maximum receive size for SASL server",
    "security.inter.broker.protocol": "Security protocol for inter-broker communication",
    "security.providers": "Custom security providers",
    "socket.connection.setup.timeout.max.ms": "Maximum timeout for socket connection setup",
    "socket.connection.setup.timeout.ms": "Timeout for socket connection setup",
    "socket.listen.backlog.size": "Socket listen backlog size",
    "socket.receive.buffer.bytes": "SO_RCVBUF buffer size for network requests (default: 100KB)",
    "socket.request.max.bytes": "Maximum size of a request (default: 100MB, protects from OOM)",
    "socket.send.buffer.bytes": "SO_SNDBUF buffer size for network requests (default: 100KB)",
    "ssl.cipher.suites": "List of enabled SSL cipher suites",
    "ssl.client.auth": "Client authentication mode: none, requested, or required",
    "ssl.enabled.protocols": "Enabled SSL/TLS protocols (e.g., TLSv1.2, TLSv1.3)",
    "ssl.endpoint.identification.algorithm": "Endpoint identification algorithm (https or empty)",
    "ssl.engine.factory.class": "Custom SSL engine factory",
    "ssl.key.password": "Password for private key in keystore",
    "ssl.keymanager.algorithm": "Key manager algorithm (default: SunX509)",
    "ssl.keystore.certificate.chain": "Certificate chain for keystore",
    "ssl.keystore.key": "Private key for keystore",
    "ssl.keystore.location": "Location of keystore file",
    "ssl.keystore.password": "Password for keystore file",
    "ssl.keystore.type": "Type of keystore (JKS, PKCS12)",
    "ssl.principal.mapping.rules": "Rules for mapping SSL principals to Kafka principals",
    "ssl.protocol": "SSL protocol (TLS, TLSv1.2, TLSv1.3)",
    "ssl.provider": "SSL provider (leave empty for default)",
    "ssl.secure.random.implementation": "SecureRandom implementation",
    "ssl.trustmanager.algorithm": "Trust manager algorithm (default: PKIX)",
    "ssl.truststore.certificates": "Trusted certificates for truststore",
    "ssl.truststore.location": "Location of truststore file",
    "ssl.truststore.password": "Password for truststore file",
    "ssl.truststore.type": "Type of truststore (JKS, PKCS12)",
    "super.users": "Semicolon-separated list of super users (full access)",
    "transaction.abort.timed.out.transaction.cleanup.interval.ms": "Interval for cleaning up timed-out transactions",
    "transaction.max.timeout.ms": "Maximum timeout for transactions (default: 15 minutes)",
    "transaction.remove.expired.transaction.cleanup.interval.ms": "Interval for removing expired transactions",
    "transaction.state.log.load.buffer.size": "Buffer size for loading transaction state",
    "transaction.state.log.min.isr": "Minimum ISR for transaction state topic (default: 2, recommended: match cluster min.insync.replicas)",
    "transaction.state.log.num.partitions": "Number of partitions for transaction state topic (default: 50)",
    "transaction.state.log.replication.factor": "Replication factor for transaction state topic (default: 3)",
    "transaction.state.log.segment.bytes": "Segment size for transaction state topic",
    "transactional.id.expiration.ms": "Expiration time for transactional IDs",
    "unclean.leader.election.enable": "Allow out-of-sync replicas (not in ISR) to become leader when no ISR replica is available. Default: false. AWS MSK: true. Risk: Enabling causes DATA LOSS - messages not yet replicated to new leader are lost. Availability vs Durability trade-off. Production: Keep false unless availability is more critical than data integrity. Never enable for financial/transactional data.",
    "zookeeper.clientCnxnSocket": "ZooKeeper client connection socket implementation",
    "zookeeper.connect": "ZooKeeper connection string (deprecated in KRaft mode)",
    "zookeeper.connection.timeout.ms": "ZooKeeper connection timeout",
    "zookeeper.max.in.flight.requests": "Maximum in-flight requests to ZooKeeper",
    "zookeeper.metadata.migration.enable": "Enable ZooKeeper to KRaft migration",
    "zookeeper.session.timeout.ms": "ZooKeeper session timeout (default: 18 seconds)",
    "zookeeper.set.acl": "Set ACL on ZooKeeper nodes",
    "zookeeper.ssl.cipher.suites": "SSL cipher suites for ZooKeeper",
    "zookeeper.ssl.client.enable": "Enable SSL for ZooKeeper client",
    "zookeeper.ssl.crl.enable": "Enable CRL for ZooKeeper SSL",
    "zookeeper.ssl.enabled.protocols": "Enabled SSL protocols for ZooKeeper",
    "zookeeper.ssl.endpoint.identification.algorithm": "Endpoint identification for ZooKeeper SSL",
    "zookeeper.ssl.keystore.location": "Keystore location for ZooKeeper SSL",
    "zookeeper.ssl.keystore.password": "Keystore password for ZooKeeper SSL",
    "zookeeper.ssl.keystore.type": "Keystore type for ZooKeeper SSL",
    "zookeeper.ssl.ocsp.enable": "Enable OCSP for ZooKeeper SSL",
    "zookeeper.ssl.protocol": "SSL protocol for ZooKeeper",
    "zookeeper.ssl.truststore.location": "Truststore location for ZooKeeper SSL",
    "zookeeper.ssl.truststore.password": "Truststore password for ZooKeeper SSL",
    "zookeeper.ssl.truststore.type": "Truststore type for ZooKeeper SSL"
  },
  "acl": {
    "Resource Type": "Type of resource this ACL applies to (Topic, Group, Cluster, TransactionalId)",
    "Resource Name": "Name of the specific resource (e.g., topic name, group name, or * for all)",
    "Resource Pattern": "How the resource name is matched: LITERAL (exact), PREFIXED (starts with), or ANY",
    "Resource Pattern Type": "How the resource name is matched: LITERAL (exact), PREFIXED (starts with), or ANY",
    "Principal": "User or service account this ACL applies to (format: User:username)",
    "Operation": "What action is allowed/denied (Read, Write, Create, Delete, Describe, Alter, etc.)",
    "Permission Type": "Whether this ACL allows or denies the operation",
    "Permission": "Whether this ACL allows or denies the operation"
  },
  "common": {
    "Status": "Current operational status",
    "Created": "When this resource was created",
    "Modified": "When this resource was last modified",
    "Last Modified": "When this resource was last modified",
    "Description": "Human-readable description",
    "Config": "Configuration settings",
    "Metadata": "Additional information about this resource",
    "Timestamp": "Time when this event or action occurred",
    "Property": "Configuration parameter name",
    "PROPERTY": "Configuration parameter name",
    "Value": "Current value of the configuration parameter",
    "VALUE": "Current value of the configuration parameter",
    "Source": "Where the configuration value originates from. Topic Override = highest priority config, Server Config = static server.properties, Kafka Default = built-in default value",
    "SOURCE": "Where the configuration value originates from. Topic Override = highest priority config, Server Config = static server.properties, Kafka Default = built-in default value"
  }
}
